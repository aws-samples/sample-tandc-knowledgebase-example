# 5.6 Amazon Bedrock - Foundation Model (FM) - Hands On

Okay, so let's go back into our providersand do a little deeper dive.So as we can see, different companiesand providers will offer different models.And the models will have different capabilities.So for example, if you choose Anthropic or Amazonor DeepSeek, or for example, Stability AI,you have different capabilities.So you're not supposed to understand which modelcan be used for what,and this is not what the exam will ask you,but it will ask you to understandwhat model can and cannot perform.For example, if you're looking at a Claude 3.5 Haiku,this one, it's a good model for all these things,for text, mainly for text, right?But if you look at a model, for example,you look at the model from Amazon,and you look at Nova Reel,this model is going to be used for text to videoor image to video.So this is important because different modelshave different capabilities,but in terms of which model is better,this is not asked for you from the exam, of course.Okay, so now let's compare models.So we can go into chats and text playgrounds.And you're going to open the Compare mode on the top right,and we'll select a model from Amazon,for example, Nova Micro,and we'll select a model from Anthropic,for example, Claude 3.5 Sonnet.Okay, so you close this configuration windowand now we have the two models side by side.And as we can see, first thing is that we can seethat Nova Micro does not support image upload.So if you upload image, it is going to be ignored.So it's very important because, well,each model will have different capabilityand this one is more pricey,but also has the ability to look at images.So based on your use case,you will be able to figure outwhich model is the most appropriate.Now if you ask a question, for example,"What are the top AWS services?"and you run it,each model is going to give you a specific answer.So here is the model Nova Micro,that's answered in a specific way,and it said EC2, S3, RDS, SageMaker, Lambda, VPC,EKS, and so on.And here we have a list as well on Claude 3.5 Sonnet,which is a much longer list.We have 20 items in here, we have 11.So as you can see, the the formattingand the way the information is presentedis very different based on these models.And you can also compare the performance.So this model was seven input tokens, 512 output tokens,and it took this long.And this model was 15 input tokens, 393 output tokens,and it took this long.So it took about four times as long.So when you compare models,it's important to compare the quality of the outputsas well as the cost and time it took to get you this output.If you have something very simple,such as "What is the capital of France?"and you run this.I'm getting too many requests.But here we have, "The capital of France is Paris."And we get a long answer.And here we'll have another answer.Here we go with different formatting.So again, it's up to you to choosewhat formatting you like mostand if you like the extra information or not,if you want a more short, shorter answer or not.And of course you can control all of these things.But it's important for you to see the type of modelsand the comparison between them.We can also have a look at customized models.So on the left hand side you click on Custom model,and here we can create a modelthat's going to be better fitted for our use case.And so we have different customization methods,we have fine-tuning, and here we provide labeled datain order to train a modelto improve the performance on a specific task.So you train it and you fine-tune it to say,"Hey, for this kind of question,I want this kind of answer."Distillation is another use casethat we won't see right now,and Continued pre-trainingis for you to give more data to your model.For example, stuff it doesn't know already.And then the model will be learning from this data.And so you continue the training.Therefore it's called Continued pre-training.So, for example,let's say we want to create a fine-tuning job.So you click on this.You select a model.For example, we choose Nova Micro.And here we enter names, so DemoCustomModel.We won't actually do it,I just wanna show you the options.So JobName and so on.So here you have VPC settings for network,but we won't take a look at it.The important part is Input data.So where do we want to provide the input datato perform this customization jobas well as validation datasets.So where is the data in Amazon is free again,to validate the fact that the output modelis doing an output that is correctbased on our pre-training.So it's to validate the factthat the custom model is working as expected.We have Hyperparameters.So these are way beyond the scope of this courseinto learning exactly how they work individually right now.But the idea is that you can tweak these parametersto ensure that the custom modelis going to be trained the way you wantwith the performance you want.So these are advanced settings,so we'll just leave them as is.Output data is where to store the model validation outputsif you provided a validation input dataset.And finally a service role to allow Bedrockto read into Amazon S3and to get this data for the trainingas well as for the validation.And then you create the fine-tuning job.Something you need to realizeis that to create a custom model,first of all, you need to provision,you need to purchase provisioned throughputs,because this is not on demand, this is specific to you.And then after this model is created,you will need provisioned throughputs againto be able to use this modelbecause this is gonna be a model just for you.So we've seen all the options to create a custom model.So I hope that was helpfuland I will see you in the next lecture.