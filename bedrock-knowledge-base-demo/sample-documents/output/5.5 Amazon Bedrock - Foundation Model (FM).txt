# 5.5 Amazon Bedrock - Foundation Model (FM)

So now let's talkabout the different options we havefor base foundation models.So we have to choose based on a lot of different factors.In the end, it's going to come down to the model types,the performance requirements you have,the capabilities of the model,the constraints you have,the compliance you need, and so on.Also, some models may provide youdifferent levels of customization.Some models may be smaller, others bigger.They could be different levels for inference,so how to basically get an output of the model.You may have different licensing agreements.You may have different requirements on context windows,so how much data you can send it to a foundation model,as well as latency,so how fast a model will come back to you with an answer.You may also have different factors,such as is the model multimodal?Which means that it can take a wide combinationof types of inputs,for example, audio, text, and video together,and also give you various types of outputs,for example, again, images, audio, video, text,but all together at the same time.So there's no clear answer.Of course, it's up for you to test,but there is something called Amazon Titan,and because this is an AWS certification we're studying for,I believe Amazon Titan is going to appear at the exam.So what is Amazon Titan?Well, it is the high-performing foundation modeldirectly from AWS.So you have different levels of Amazon Titan,but it can do images, text,and you also have multimodal choices,all via the same API you have on Amazon Bedrock.As well, it can be customized with your own data,so you can fine-tune Amazon Titan,and that can be very handy.Also, for example, to make a decision on a model,usually, the smaller modelsare going to be more cost-effective,but they usually know less things.So it's a bunch of balancing acts,really, based on what your business needs is on.So let's have a look at four modelsto see if we can understand a little bithow our process would go into.So we have Amazon Titan,and we're going to compare Amazon Titan Text Express.We have, and I'll call it Llama, but it may be Yama,Llama-2, which is some model out of Meta.We have Claude out of from Entropic,and then we have Stability AI,which created something called Stable Diffusion.So first of all,the last model is for image generation only.So if you want just image,maybe the last model can build for you.But, like, for the other ones,you have different kinds of capabilities.So if we look at features, for example,well, Amazon Titan can do text,and it can do it in 100-plus languages.Llama-2 can do large-scale tasks, dialogue, and in English.And Claude can have also text generation and also language.So it comes down to testinghow the model reacts to your inputs.And one thing that may be very importantis the number of tokens you can haveas an input to the model.So Amazon, we have 8K tokens.Llama-2, we have 4K tokens,and Claude, we have 200K tokens.So that means that on Claude,you can send a lot more words into your context windows.And so Claude will have more memoryand will be able to intake a bigger input,which may be very important.For example, you may want to send a big context windowwhen you're dealing with a big code baseor when you have to read an entire bookand ask questions about that book.Then maybe Claude is going to be a better fit.So the use cases really depends on the models,but to be fair, all these models start to look the sameand have the same kind of capabilities.They're all converging towards the same thing.So it's down to mainly testing.But so Amazon Titan is going to be around content creation,classification, and education.Llama-2 is going to be around tech generationand customer service.Claude could be for analysis,forecasting, and document comparison.This is mainly due to the fact it has higher number of tokenas an input,and Stability AI is going to be for image creation,for advertising, media, and so on.And so pricing can be a big factor again.So here, the pricing is givenfor 1,000 tokens given to the model.So as you can see, Amazon Titan Text Express is very cheap.It's much cheaper than Llama-2,and Llama-2 is much cheaper than Claude.So again, this could be a big onebecause, obviously, the more expensive modelsmay give you better answers,but sometimes the less expensive modelscan still give you good answers,but they're going to be a lot more cost-effective.And as well for Stability AIbased on the image you generate,it may cost you as well some money.So be consciousbecause you can very, very quickly accumulatea lot of costs with AI.So I hope you liked it,and I will see you in the next lecture.